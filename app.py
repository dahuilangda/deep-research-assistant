import requests
import time
import os
import re

import streamlit as st

from dotenv import load_dotenv
load_dotenv()

BACKEND_HOST = os.getenv("BACKEND_HOST")
BACKEND_PORT = os.getenv("BACKEND_PORT")

API_BASE = f"http://{BACKEND_HOST}:{BACKEND_PORT}"

# æœ¬åœ°ä¸´æ—¶æ–‡ä»¶å­˜å‚¨ç›®å½•
FILE_PATH = os.getenv('TMP_FILE_PATH')

st.set_page_config(page_title="Deep Research ç ”ç©¶åŠ©æ‰‹", layout="centered")
st.title("ğŸ” Deep Research ç ”ç©¶åŠ©æ‰‹")

# é€šè¿‡å•é€‰é¡¹è®©ç”¨æˆ·é€‰æ‹©ä¸åŒæŸ¥è¯¢æ–¹å¼
query_type = st.radio(
    "è¯·é€‰æ‹©æŸ¥è¯¢æ–¹å¼:",
    ["ä¸Šä¼ æ–‡ä»¶", "è¾“å…¥ç½‘å€", "ç½‘ç»œæœç´¢", "ç»„åˆæŸ¥è¯¢"],
    key="query_type_radio"
)

# è¾“å…¥é—®é¢˜ï¼ˆæ–‡æœ¬åŒºåŸŸï¼‰
question = st.text_area(
    "è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š",
    placeholder="ä¾‹å¦‚ï¼šè¿™ç¯‡æ–‡ç« çš„ç ”ç©¶ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
    height=100,
    key="question_text_area"
)

# --- æ ¹æ®é€‰æ‹©çš„æŸ¥è¯¢æ–¹å¼æ˜¾ç¤ºç›¸åº”çš„è¾“å…¥æ§ä»¶ ---
uploaded_files = None
urls_input = "" # ä¿®æ”¹å˜é‡åä»¥é¿å…ä¸ url_list å†²çª
search_web_flag = False # ç”¨äºè¡¥å……æ–‡ä»¶/URLçš„è”ç½‘æœç´¢æ ‡å¿—

if query_type == "ä¸Šä¼ æ–‡ä»¶":
    uploaded_files = st.file_uploader("é€‰æ‹©æ–‡ä»¶", accept_multiple_files=True, key="file_uploader_files")
    search_web_flag = st.checkbox("è”ç½‘è¡¥å……èµ„æ–™ (ä»ç½‘ç»œæœç´¢ä¿¡æ¯ä»¥å¢å¼ºç­”æ¡ˆ)", key="web_complement_files")
elif query_type == "è¾“å…¥ç½‘å€":
    urls_input = st.text_area("è¯·è¾“å…¥ç½‘å€ï¼ˆå¯å¤šä¸ªï¼Œæ¯è¡Œä¸€ä¸ªï¼‰", height=100, key="url_input_webs")
    search_web_flag = st.checkbox("è”ç½‘è¡¥å……èµ„æ–™ (ä»ç½‘ç»œæœç´¢ä¿¡æ¯ä»¥å¢å¼ºç­”æ¡ˆ)", key="web_complement_webs")
elif query_type == "ç½‘ç»œæœç´¢":
    st.info("æ­¤æ¨¡å¼å°†ç›´æ¥åœ¨ç½‘ç»œä¸Šæœç´¢ç­”æ¡ˆã€‚")
    # åç«¯ /api/search é»˜è®¤è¿›è¡Œç½‘ç»œæœç´¢ï¼Œå‰ç«¯æ— éœ€é¢å¤–å‚æ•°æ§åˆ¶æœç´¢è¡Œä¸ºæœ¬èº«
    # å¦‚æœéœ€è¦å¦‚ "science" æˆ– "news" çš„æ¨¡å¼ï¼Œåç«¯ DeepSearch agent éœ€è¦æ”¯æŒæ­¤åŒºåˆ†
elif query_type == "ç»„åˆæŸ¥è¯¢":
    uploaded_files = st.file_uploader("é€‰æ‹©æ–‡ä»¶ (å¯é€‰)", accept_multiple_files=True, key="file_uploader_combined")
    urls_input = st.text_area("è¯·è¾“å…¥ç½‘å€ (å¯é€‰, æ¯è¡Œä¸€ä¸ª)", height=100, key="url_input_combined")
    search_web_flag = st.checkbox("è”ç½‘è¡¥å……èµ„æ–™ (è‹¥æä¾›æ–‡ä»¶/ç½‘å€åˆ™è¡¥å……æœç´¢ï¼›å¦åˆ™å°†è¿›è¡Œç½‘ç»œæœç´¢)", key="web_complement_combined")

# æäº¤æŒ‰é’®
submit_button = st.button("ğŸš€ å¼€å§‹åˆ†æ", key="submit_button_main")

if submit_button:
    if not question.strip():
        st.warning("è¯·è¾“å…¥ä½ çš„é—®é¢˜ã€‚")
        st.stop()

    payload = {"question": question}
    api_endpoint = ""
    job_started_message = ""
    processed_file_paths = [] # ç”¨äºè·Ÿè¸ªæœ¬æ¬¡ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„ï¼Œä»¥ä¾¿åç»­æ¸…ç†

    # æ ¹æ®æŸ¥è¯¢ç±»å‹å‡†å¤‡æ•°æ®
    if query_type == "ä¸Šä¼ æ–‡ä»¶":
        if not uploaded_files:
            st.warning("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶ã€‚")
            st.stop()
        current_file_paths = []
        for f_upload in uploaded_files:
            # ä½¿ç”¨å”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶åä»¥é¿å…å†²çª (å¦‚æœéœ€è¦)
            # unique_filename = f"{uuid.uuid4().hex}_{f_upload.name}"
            # filepath = os.path.join(FILE_PATH, unique_filename)
            filepath = os.path.join(FILE_PATH, f_upload.name) # ä¿æŒåŸæ ·ï¼Œä½†æ³¨æ„åŒåæ–‡ä»¶è¦†ç›–
            try:
                with open(filepath, "wb") as out_file:
                    out_file.write(f_upload.read())
                current_file_paths.append(filepath)
                processed_file_paths.append(filepath)
                # print(f"DEBUG: Saved file {filepath}")
            except Exception as e:
                st.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {f_upload.name}: {e}")
                st.stop()
        payload["file_paths"] = current_file_paths
        payload["search_web_flag"] = search_web_flag
        api_endpoint = f"{API_BASE}/api/files"
        job_started_message = "æ–‡ä»¶å¤„ç†ä»»åŠ¡å·²å¼€å§‹ã€‚"

    elif query_type == "è¾“å…¥ç½‘å€":
        if not urls_input.strip():
            st.warning("è¯·è¾“å…¥ç½‘å€ã€‚")
            st.stop()
        url_list = [u.strip() for u in urls_input.splitlines() if u.strip()]
        if not url_list:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘å€ã€‚")
            st.stop()
        payload["urls"] = url_list
        payload["search_web_flag"] = search_web_flag
        api_endpoint = f"{API_BASE}/api/webs"
        job_started_message = "ç½‘é¡µå†…å®¹å¤„ç†ä»»åŠ¡å·²å¼€å§‹ã€‚"

    elif query_type == "ç½‘ç»œæœç´¢":
        api_endpoint = f"{API_BASE}/api/search"
        job_started_message = "ç½‘ç»œæœç´¢ä¸åˆ†æä»»åŠ¡å·²å¼€å§‹ã€‚"

    elif query_type == "ç»„åˆæŸ¥è¯¢":
        current_file_paths = []
        if uploaded_files:
            for f_upload in uploaded_files:
                filepath = os.path.join(FILE_PATH, f_upload.name)
                try:
                    with open(filepath, "wb") as out_file:
                        out_file.write(f_upload.read())
                    current_file_paths.append(filepath)
                    processed_file_paths.append(filepath)
                    # print(f"DEBUG: Saved file {filepath}")
                except Exception as e:
                    st.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {f_upload.name}: {e}")
                    st.stop()

        url_list = []
        if urls_input.strip():
            url_list = [u.strip() for u in urls_input.splitlines() if u.strip()]

        if not current_file_paths and not url_list and not search_web_flag:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›ä»»ä½•è¾“å…¥ï¼Œå¹¶ä¸”æ²¡æœ‰å‹¾é€‰è”ç½‘è¡¥å……ï¼Œæç¤ºä»–ä»¬
            st.warning("è¯·è‡³å°‘æä¾›æ–‡ä»¶ã€ç½‘å€ï¼Œæˆ–å‹¾é€‰â€œè”ç½‘è¡¥å……èµ„æ–™â€ä»¥è¿›è¡Œçº¯ç½‘ç»œæœç´¢ã€‚")
            st.stop()
        
        payload["file_paths"] = current_file_paths if current_file_paths else None
        payload["urls"] = url_list if url_list else None
        payload["search_web_flag"] = search_web_flag
        api_endpoint = f"{API_BASE}/api/combine"
        job_started_message = "ç»„åˆå¤„ç†ä»»åŠ¡å·²å¼€å§‹ã€‚"
    else:
        st.error("æ— æ•ˆçš„æŸ¥è¯¢ç±»å‹ã€‚")
        st.stop()

    # --- æäº¤åˆ°åç«¯å¹¶è½®è¯¢ç»“æœ ---
    job_id = None
    if api_endpoint:
        with st.spinner("æ­£åœ¨æäº¤ä»»åŠ¡ï¼Œè¯·ç¨ç­‰..."):
            try:
                # print(f"DEBUG: Submitting to: {api_endpoint} with payload: {payload}")
                res = requests.post(api_endpoint, json=payload)
                res.raise_for_status()
                response_data = res.json()
                if "job_id" not in response_data:
                    st.error(f"ä»»åŠ¡æäº¤å“åº”é”™è¯¯ï¼šæœªæ‰¾åˆ° job_idã€‚å“åº”: {response_data}")
                    st.stop()
                job_id = response_data["job_id"]
                st.success(f"ä»»åŠ¡å·²æäº¤ï¼Job ID: {job_id}. {job_started_message}")
            except requests.exceptions.RequestException as e:
                st.error(f"æäº¤ä»»åŠ¡å¤±è´¥ï¼š{e}")
                if e.response is not None:
                    st.error(f"åç«¯å“åº”: {e.response.status_code} - {e.response.text}")
                st.stop()
            except Exception as e:
                st.error(f"æäº¤ä»»åŠ¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                st.stop()

    if job_id:
        progress_bar = st.progress(0)
        status_text_area = st.empty() # ç”¨äºæ˜¾ç¤ºè½®è¯¢çŠ¶æ€çš„æ–‡æœ¬åŒºåŸŸ

        polling_attempts = int(os.getenv("POLLING_ATTEMPTS", 240))  # æœ€å¤§è½®è¯¢æ¬¡æ•° (ä¾‹å¦‚ 240 * 5ç§’ = 20åˆ†é’Ÿ)
        for i in range(polling_attempts):
            try:
                status_res = requests.get(f"{API_BASE}/api/job/{job_id}")
                status_res.raise_for_status()
                job_data = status_res.json()

                progress = (i + 1) / polling_attempts
                progress_bar.progress(min(progress, 1.0))

                if job_data["status"] == "completed":
                    status_text_area.success("âœ… åˆ†æå®Œæˆï¼")
                    progress_bar.progress(1.0)

                    answer = job_data.get("result", {}).get("answer", "æœªèƒ½è·å–åˆ°ç­”æ¡ˆã€‚")
                    references = job_data.get("result", {}).get("retrieved_results", [])
                    consumed_tokens = job_data.get("result", {}).get("consumed_tokens", "æœªçŸ¥")

                    # æ¸…ç†ç­”æ¡ˆä¸­çš„ <think> æ ‡ç­¾
                    if isinstance(answer, str) and "<think>" in answer and "</think>" in answer:
                        # ä½¿ç”¨ re.split æ¥å¤„ç†å¯èƒ½çš„å¤šè¡Œ <think> å—æˆ–ä¸è§„èŒƒçš„æ¢è¡Œ
                        parts = re.split(r'<think>.*?</think>\s*', answer, flags=re.DOTALL)
                        answer = parts[-1].strip()


                    st.markdown("### ğŸ“ åˆ†æç»“æœ:")
                    st.markdown(answer, unsafe_allow_html=True)

                    if references:
                        st.markdown("### ğŸ“š å‚è€ƒæ–‡çŒ®:")
                        for idx, ref in enumerate(references, start=1):
                            ref_text = ref.get('text', 'æ— æ–‡æœ¬å†…å®¹')
                            ref_source = ref.get('reference', 'æœªçŸ¥æ¥æº')
                            ref_score = ref.get('score', None)
                            display_source = ref_source
                            if len(ref_source) > 100: # æˆªæ–­è¿‡é•¿çš„æ¥æºä»¥é€‚åº”æ ‡é¢˜
                                display_source = ref_source[:97] + "..."
                            
                            expander_title = f"{idx}. {display_source}"
                            if ref_score is not None:
                                expander_title += f" (ç›¸å…³æ€§: {ref_score:.2f})"

                            with st.expander(expander_title):
                                st.caption(f"æ¥æº: {ref_source}")
                                st.markdown(ref_text[:1000] + "..." if len(ref_text) > 1000 else ref_text, unsafe_allow_html=True)
                    
                    st.markdown(f"--- \n*Tokens æ¶ˆè€—: {consumed_tokens}*")
                    
                    # æ¸…ç†æœ¬æ¬¡ä»»åŠ¡ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
                    if processed_file_paths:
                        # print(f"DEBUG: Attempting to clean files: {processed_file_paths}")
                        for p_path in processed_file_paths:
                            try:
                                if os.path.exists(p_path):
                                    os.remove(p_path)
                                    # print(f"DEBUG: Successfully removed temp file {p_path}")
                            except Exception as e_rm:
                                st.warning(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {p_path}: {e_rm}")
                    break
                elif job_data["status"] == "failed":
                    status_text_area.error(f"âŒ ä»»åŠ¡å¤±è´¥ï¼š{job_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    progress_bar.progress(1.0)
                    break
                elif job_data["status"] == "processing":
                    status_text_area.info(f"â³ ä»»åŠ¡å¤„ç†ä¸­... (å°è¯• {i+1}/{polling_attempts})")
                elif job_data["status"] == "pending":
                    status_text_area.info(f"â³ ä»»åŠ¡å¾…å¤„ç†... (å°è¯• {i+1}/{polling_attempts})")
                else:
                    status_text_area.warning(f"âš ï¸ ä»»åŠ¡çŠ¶æ€æœªçŸ¥: {job_data['status']} (å°è¯• {i+1}/{polling_attempts})")
                
                time.sleep(int(os.getenv("POLL_INTERVAL_SECONDS", 5))) # è½®è¯¢é—´éš”

            except requests.exceptions.RequestException as e:
                status_text_area.error(f"è½®è¯¢çŠ¶æ€å¤±è´¥ (å°è¯• {i+1}/{polling_attempts}): {e}")
                time.sleep(10) # ç½‘ç»œé”™è¯¯æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
            except Exception as e:
                status_text_area.error(f"å¤„ç†çŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯ (å°è¯• {i+1}/{polling_attempts}): {e}")
                time.sleep(10)
        else:
            status_text_area.warning("â° åˆ†æè¶…æ—¶æˆ–æœªèƒ½è·å–æœ€ç»ˆçŠ¶æ€ã€‚è¯·æ£€æŸ¥åç«¯æ—¥å¿—æˆ–ç¨åå†è¯•ã€‚")
            if job_id:
                 st.info(f"ä½ å¯ä»¥ç¨åä½¿ç”¨ Job ID: {job_id} é€šè¿‡ `/api/job/{job_id}` ç«¯ç‚¹æŸ¥è¯¢æœ€ç»ˆçŠ¶æ€ã€‚")